{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import neurokit2 as nk\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ecg/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n",
      "cuda\n",
      "Task: finetune\n",
      "Dataset Name: ptb-xl\n",
      "Train Data Path: /root/data/ptb-xl/train.txt\n",
      "Model Name: FocusMae\n",
      "Mask Type: period\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from main import parse_args as parse_args_main\n",
    "\n",
    "def main(args):\n",
    "    # 在这里使用 args 进行训练或其他操作\n",
    "    args=parse_args_main()\n",
    "    print(f\"Task: {args.task}\")\n",
    "    print(f\"Dataset Name: {args.dataset_name}\")\n",
    "    print(f\"Train Data Path: {args.train_data_path}\")\n",
    "    print(f\"Model Name: {args.model_name}\")\n",
    "    print(f\"Mask Type: {args.mask_type}\")\n",
    "    return args\n",
    "    # 其他代码...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟命令行参数\n",
    "    sys.argv = [\n",
    "        'main.py',  # 通常是脚本名\n",
    "        '--task', 'finetune',\n",
    "        '--dataset_name', 'ptb-xl',\n",
    "        '--train_data_path', '/root/data/ptb-xl/train.txt',\n",
    "        '--val_data_path', '/root/data/ptb-xl/val.txt',\n",
    "        '--model_name', 'FocusMae',\n",
    "        '--mask_type', 'period',\n",
    "        # 添加其他必要的参数\n",
    "    ]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Pretrain or finetune model')\n",
    "    # 添加参数\n",
    "    parser.add_argument('--task', type=str, required=True, help='Task to perform')\n",
    "    parser.add_argument('--dataset_name', type=str, required=True, help='Name of the dataset')\n",
    "    parser.add_argument('--train_data_path', type=str, required=True, help='Path to the training data')\n",
    "    parser.add_argument('--val_data_path', type=str, required=True, help='Path to the validation data')\n",
    "    parser.add_argument('--model_name', type=str, required=True, default='FocusMae',help='Name of the model to use')\n",
    "    parser.add_argument('--mask_type', type=str, default='period', help='Type of mask to use')  \n",
    "    parser.add_argument('--ckpt_path', type=str, default='/root/ecg_ai/FocusECG/FocusECG/min_val_loss=34.49940490722656.pth', help='Type of mask to use')  \n",
    "    parsed_args=parse_args_main()\n",
    "    # 解析参数\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    for key, value in vars(parsed_args).items():\n",
    "        if value is not None:\n",
    "            setattr(args, key, value)\n",
    "\n",
    "    # 调用主函数\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_peaks_ratio(mask,all_r_peaks):\n",
    "    # 定义参数\n",
    "    num_samples = 512\n",
    "    num_patches = 30\n",
    "    patch_size = 75\n",
    "\n",
    "    # 初始化一个数组来存储每个样本的 R 波在 mask 为 0 的比率\n",
    "    r_peaks_ratio = np.zeros(num_samples)\n",
    "\n",
    "    # 计算每个样本的 R 波比率\n",
    "    for sample_idx, r_peaks in enumerate(all_r_peaks):\n",
    "        # 计算每个 R 波位置所属的 patch 索引\n",
    "        patch_indices = r_peaks\n",
    "        \n",
    "        # 计算 R 波在 mask 为 0 的数量\n",
    "        count = 0\n",
    "        for patch_idx in patch_indices:\n",
    "            if patch_idx < num_patches and mask[sample_idx, patch_idx] == 0:  # 确保索引不超出范围且 mask 为 0\n",
    "                count += 1\n",
    "        \n",
    "            # 计算比率\n",
    "        r_peaks_ratio[sample_idx] = count / num_patches if len(r_peaks) > 0 else 0\n",
    "\n",
    "    # 转换为 torch.Tensor 并调整形状\n",
    "    r_peaks_ratio_tensor = torch.tensor(r_peaks_ratio).view(num_samples, 1)\n",
    "    overall_average = r_peaks_ratio_tensor.mean()\n",
    "    return overall_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_r_peaks_ratio(x):\n",
    "    # 假设 x 是你的 ECG 信号，形状为 (512, 1, 2250)\n",
    "    all_r_peaks = []\n",
    "\n",
    "    for sample_idx in range(x.shape[0]):  # 遍历每个样本\n",
    "        ecg_signal = x[sample_idx, 0].cpu().numpy()  # 将信号展平成一维数组\n",
    "\n",
    "        # 预处理信号\n",
    "        ecg_cleaned = nk.ecg_clean(ecg_signal, sampling_rate=250)\n",
    "\n",
    "        # 检测 R 波\n",
    "        _, r_peaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=250)\n",
    "\n",
    "        # 获取 R 波位置\n",
    "        patch_size=75\n",
    "        r_peak_indices = r_peaks['ECG_R_Peaks']// patch_size\n",
    "        all_r_peaks.append(r_peak_indices)\n",
    "    return all_r_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_test import get_model\n",
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x Block(\n",
       "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (q_norm): Identity()\n",
       "      (k_norm): Identity()\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls1): Identity()\n",
       "    (drop_path1): Identity()\n",
       "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (drop1): Dropout(p=0.0, inplace=False)\n",
       "      (norm): Identity()\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (drop2): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (ls2): Identity()\n",
       "    (drop_path2): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pre_train_model.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'period'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.mask_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 247/247 [45:27<00:00, 11.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.5826, dtype=torch.float64)\n",
      "247\n",
      "所有批次的 R 波比率的平均值:\n",
      "tensor(0.0833, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import PretrainDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from config import FocusMaePreTrainConfig as PreTrainConfig\n",
    "from finetune_test import get_model\n",
    "import signal\n",
    "from tqdm import tqdm\n",
    "def dataloader_signal_handle(worker_id):\n",
    "    def signal_handler(sig, frame):\n",
    "        pass\n",
    "    signal.signal(signal.SIGTERM, signal_handler)\n",
    "total_sum = 0\n",
    "total_count = 0\n",
    "train_data_path=\"/root/data/FocusMAE/train.txt\"\n",
    "train_dataset = PretrainDataset(train_data_path)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, worker_init_fn=dataloader_signal_handle,pin_memory=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(41)\n",
    "torch.cuda.manual_seed(41)\n",
    "print(device)\n",
    "for batch in tqdm(train_dataloader, desc=\"Processing Batches\"):\n",
    "    model = get_model(args)\n",
    "    batch = batch.to(device)\n",
    "    all_r_peaks=check_r_peaks_ratio(batch)\n",
    "    pred_img,mask,info_scores,mask_probs= model.pre_train_model.forward_info_score(batch)\n",
    "    # mask=generate_mask(batch)\n",
    "    r_peaks_ratio_tensor=calculate_r_peaks_ratio(mask,all_r_peaks)\n",
    "    # 累加当前批次的总和和数量\n",
    "    total_sum += r_peaks_ratio_tensor\n",
    "    total_count += 1\n",
    "\n",
    "# 计算所有批次的平均值\n",
    "print(total_sum)\n",
    "print(total_count)\n",
    "overall_average = total_sum / total_count\n",
    "\n",
    "print(\"所有批次的 R 波比率的平均值:\")\n",
    "print(overall_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from main import parse_args as parse_args_main\n",
    "\n",
    "def main(args):\n",
    "    # 在这里使用 args 进行训练或其他操作\n",
    "    args=parse_args_main()\n",
    "    print(f\"Task: {args.task}\")\n",
    "    print(f\"Dataset Name: {args.dataset_name}\")\n",
    "    print(f\"Train Data Path: {args.train_data_path}\")\n",
    "    print(f\"Model Name: {args.model_name}\")\n",
    "    print(f\"Mask Type: {args.mask_type}\")\n",
    "    return args\n",
    "    # 其他代码...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟命令行参数\n",
    "    sys.argv = [\n",
    "        'main.py',  # 通常是脚本名\n",
    "        '--task', 'finetune',\n",
    "        '--dataset_name', 'ptb-xl',\n",
    "        '--train_data_path', '/root/data/ptb-xl/train.txt',\n",
    "        '--val_data_path', '/root/data/ptb-xl/val.txt',\n",
    "        '--model_name', 'FocusMae',\n",
    "        '--mask_type', 'period',\n",
    "        # 添加其他必要的参数\n",
    "    ]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Pretrain or finetune model')\n",
    "    # 添加参数\n",
    "    parser.add_argument('--task', type=str, required=True, help='Task to perform')\n",
    "    parser.add_argument('--dataset_name', type=str, required=True, help='Name of the dataset')\n",
    "    parser.add_argument('--train_data_path', type=str, required=True, help='Path to the training data')\n",
    "    parser.add_argument('--val_data_path', type=str, required=True, help='Path to the validation data')\n",
    "    parser.add_argument('--model_name', type=str, required=True, default='FocusMae',help='Name of the model to use')\n",
    "    parser.add_argument('--mask_type', type=str, default='period', help='Type of mask to use')  \n",
    "    parsed_args=parse_args_main()\n",
    "    # 解析参数\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    for key, value in vars(parsed_args).items():\n",
    "        if value is not None:\n",
    "            setattr(args, key, value)\n",
    "\n",
    "    # 调用主函数\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_test import get_model\n",
    "if __name__ == '__main__':\n",
    "    model = get_model(args)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (pre_train_model): MaskedAutoencoderViT(\n",
       "    (patch_embed): patchEmbed(\n",
       "      (norm): LayerNorm((75,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (timeweight): TimeSeriesWeighting(\n",
       "      (norm): LayerNorm((75,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=75, out_features=768, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norms): ModuleList(\n",
       "      (0-3): 4 x LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder_embed): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (decoder_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "    (decoder_pred): Linear(in_features=256, out_features=75, bias=True)\n",
       "  )\n",
       "  (classifier_head): MlpHeadV1(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.8, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (5): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.8, inplace=False)\n",
       "      (8): Linear(in_features=384, out_features=4, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img,mask,info_scores,mask_probs= model.pre_train_model.forward_info_score(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2130, 0.1104, 0.9536,  ..., 0.0835, 0.8127, 0.6543],\n",
       "        [0.3799, 0.6124, 0.7904,  ..., 0.3525, 0.1819, 0.5738],\n",
       "        [0.6264, 0.4535, 0.0104,  ..., 0.7946, 0.9982, 0.6876],\n",
       "        ...,\n",
       "        [0.9192, 0.6501, 0.2702,  ..., 0.5882, 0.8731, 0.4438],\n",
       "        [0.2699, 0.0437, 0.7667,  ..., 0.4377, 0.9402, 0.1887],\n",
       "        [0.9724, 0.2704, 0.8739,  ..., 0.4435, 0.7381, 0.1922]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_mask(x):\n",
    "        # 定义参数\n",
    "    num_samples = 512\n",
    "    num_patches = 30\n",
    "    num_zeros = 7\n",
    "\n",
    "    # 初始化 mask\n",
    "    mask_random = np.ones((num_samples, num_patches))\n",
    "\n",
    "    # 为每个样本随机选择 7 个位置设置为 0\n",
    "    for i in range(num_samples):\n",
    "        zero_indices = np.random.choice(num_patches, num_zeros, replace=False)\n",
    "        mask_random[i, zero_indices] = 0\n",
    "    return mask_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "\n",
    "# 假设 x 是你的 ECG 信号，形状为 (512, 1, 2250)\n",
    "all_r_peaks = []\n",
    "\n",
    "for sample_idx in range(x.shape[0]):  # 遍历每个样本\n",
    "    ecg_signal = x[sample_idx, 0].cpu().numpy()  # 将信号展平成一维数组\n",
    "\n",
    "    # 预处理信号\n",
    "    ecg_cleaned = nk.ecg_clean(ecg_signal, sampling_rate=250)\n",
    "\n",
    "    # 检测 R 波\n",
    "    _, r_peaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=250)\n",
    "\n",
    "    # 获取 R 波位置\n",
    "    patch_size=75\n",
    "    r_peak_indices = r_peaks['ECG_R_Peaks']// patch_size\n",
    "    all_r_peaks.append(r_peak_indices)\n",
    "\n",
    "# # 打印所有样本的 R 波位置\n",
    "# for idx, r_peaks in enumerate(all_r_peaks):\n",
    "#     print(f\"样本 {idx} 的 R 波位置: {r_peaks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 假设 all_r_peaks 是一个包含每个样本 R 波位置的列表\n",
    "# 假设 mask 是一个形状为 (512, 30) 的数组\n",
    "\n",
    "# 定义参数\n",
    "num_samples = 512\n",
    "num_patches = 30\n",
    "patch_size = 75\n",
    "\n",
    "# 初始化一个数组来存储每个样本的 R 波在 mask 为 0 的比率\n",
    "r_peaks_ratio = np.zeros(num_samples)\n",
    "\n",
    "# 计算每个样本的 R 波比率\n",
    "for sample_idx, r_peaks in enumerate(all_r_peaks):\n",
    "    # 计算每个 R 波位置所属的 patch 索引\n",
    "    patch_indices = r_peaks\n",
    "    \n",
    "    # 计算 R 波在 mask 为 0 的数量\n",
    "    count = 0\n",
    "    for patch_idx in patch_indices:\n",
    "        if patch_idx < num_patches and mask_random[sample_idx, patch_idx] == 0:  # 确保索引不超出范围且 mask 为 0\n",
    "            count += 1\n",
    "    \n",
    "    # 计算比率\n",
    "    r_peaks_ratio[sample_idx] = count / num_patches if len(r_peaks) > 0 else 0\n",
    "\n",
    "# 转换为 torch.Tensor 并调整形状\n",
    "r_peaks_ratio_tensor = torch.tensor(r_peaks_ratio).view(num_samples, 1)\n",
    "overall_average = r_peaks_ratio_tensor.mean()\n",
    "# 打印结果\n",
    "print(\"R 波在 mask 为 0 的总体比率:\")\n",
    "print(overall_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_peaks_ratio_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_with_mask_probs(signal, mask_probs, patch_size=30):\n",
    "    plt.clf()\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    fig.patch.set_facecolor('white')  # 设置白色背景\n",
    "    \n",
    "    # 绘制原始信号\n",
    "    ax1.plot(range(len(signal)), signal, color='#1f77b4', linewidth=1.5, label='Signal')\n",
    "    ax1.set_title('Signal with Information Scores', fontsize=12, pad=10)\n",
    "    ax1.set_ylabel('Amplitude', fontsize=10)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 添加patch分割和概率值\n",
    "    for i in range(len(mask_probs)):\n",
    "        # patch边界\n",
    "        x_pos = i * patch_size\n",
    "        ax1.axvline(x=x_pos, color='#ff7f0e', linestyle='--', alpha=0.2)\n",
    "        \n",
    "        # 半透明颜色块\n",
    "        ax1.axvspan(i*patch_size, (i+1)*patch_size, \n",
    "                   alpha=float(mask_probs[i])*0.3,  # 降低透明度\n",
    "                   color='#ff7f0e',\n",
    "                   label=f'Patch {i}' if i == 0 else \"\")\n",
    "        \n",
    "        # 概率值标注\n",
    "        patch_center = i * patch_size + patch_size/2\n",
    "        score = float(mask_probs[i])\n",
    "        if score > 0.2:  # 只显示重要性较高的分数\n",
    "            ax1.text(patch_center, ax1.get_ylim()[1], \n",
    "                    f'{score:.2f}', \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='bottom',\n",
    "                    rotation=90,\n",
    "                    fontsize=8,\n",
    "                    color='#2f4f4f')\n",
    "    \n",
    "    # 绘制概率条形图\n",
    "    patch_positions = np.arange(len(mask_probs))\n",
    "    bars = ax2.bar(patch_positions, mask_probs.cpu().detach().numpy(), \n",
    "                  alpha=0.6, color='#ff7f0e', width=0.8)\n",
    "    \n",
    "    # 在柱状图上添加数值标签\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0.5:  # 只显示重要性较高的分数\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax2.set_title('Information Scores per Patch', fontsize=12, pad=10)\n",
    "    ax2.set_xlabel('Patch Index', fontsize=10)\n",
    "    ax2.set_ylabel('Score', fontsize=10)\n",
    "    ax2.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 使用示例：\n",
    "sample_idx = 110  # 选择第一个样本\n",
    "signal = x[sample_idx, 0].cpu().numpy()  # [1200]\n",
    "probs = info_scores[sample_idx].detach()  # [40]\n",
    "plot_signal_with_mask_probs(signal, probs, patch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_with_masks_and_pred(signal, mask_probs, mask, pred_signal, probs,patch_size=75):\n",
    "    plt.clf()\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # 1. 绘制原始信号和mask信息\n",
    "    ax1.plot(range(len(signal)), signal, color='#1f77b4', linewidth=1.5, label='Signal')\n",
    "    ax1.set_title('Original Signal with Mask Information', fontsize=12, pad=10)\n",
    "    ax1.set_ylabel('Amplitude', fontsize=10)\n",
    "    \n",
    "    # 添加patch分割和遮盖信息\n",
    "    for i in range(len(probs)):\n",
    "        x_pos = i * patch_size\n",
    "        ax1.axvline(x=x_pos, color='gray', linestyle='--', alpha=0.2)\n",
    "        \n",
    "        # 为每个patch添加颜色块\n",
    "        if mask[i] == 1:  # 保留的patch\n",
    "            ax1.axvspan(i*patch_size, (i+1)*patch_size, \n",
    "                       alpha=0.2,\n",
    "                       color='green',\n",
    "                       label='Kept' if i == 0 else \"\")\n",
    "        else:  # 被遮盖的patch\n",
    "            ax1.axvspan(i*patch_size, (i+1)*patch_size, \n",
    "                       alpha=0.2,\n",
    "                       color='red',\n",
    "                       label='Masked' if i == 0 else \"\")\n",
    "        \n",
    "        # 添加概率值\n",
    "        patch_center = i * patch_size + patch_size/2\n",
    "        score = float(probs[i])\n",
    "        ax1.text(patch_center, ax1.get_ylim()[1], \n",
    "                f'{score:.2f}', \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='bottom',\n",
    "                rotation=90,\n",
    "                fontsize=8)\n",
    "    \n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 2. 绘制概率条形图\n",
    "    patch_positions = np.arange(len(mask_probs))\n",
    "    bars = ax2.bar(patch_positions, mask_probs.cpu().detach().numpy(), \n",
    "                  alpha=0.6,\n",
    "                  color=['green' if m == 1 else 'red' for m in mask],\n",
    "                  width=0.8)\n",
    "    \n",
    "    ax2.set_title('Mask Probabilities per Patch', fontsize=12, pad=10)\n",
    "    ax2.set_xlabel('Patch Index', fontsize=10)\n",
    "    ax2.set_ylabel('Probability', fontsize=10)\n",
    "    ax2.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # 3. 绘制重建信号\n",
    "    ax3.plot(range(len(pred_signal)), pred_signal, color='#2ca02c', linewidth=1.5, label='Reconstructed')\n",
    "    ax3.set_title('Reconstructed Signal', fontsize=12, pad=10)\n",
    "    ax3.set_xlabel('Time', fontsize=10)\n",
    "    ax3.set_ylabel('Amplitude', fontsize=10)\n",
    "    ax3.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 使用示例：\n",
    "sample_idx = 50  # 选择样本\n",
    "signal = x[sample_idx, 0].cpu().numpy()  #\n",
    "mask_probs_noise = mask_probs[sample_idx].detach()  \n",
    "mask_sample = mask[sample_idx]  # [40]\n",
    "pred = pred_img[sample_idx, 0].cpu().detach().numpy()  \n",
    "probs = info_scores[sample_idx].detach()  # [40]\n",
    "plot_signal_with_masks_and_pred(signal, mask_probs_noise, mask_sample, pred, probs,patch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
